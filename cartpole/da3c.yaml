environment:
  run: python environment/training.py
  name: CartPole-v0
  max_episodes: 1000
  infinite_run: false

relaax-metrics-server:
  enable_unknown_metrics: false
  metrics:
    episode_reward: true
    server_latency: true
    action: true
    mu: true
    sigma2: true
    critic: true

  bind: localhost:7002
  metrics_dir: logs/metrics
  log_metrics_to_console: false
  log_level: INFO

relaax-parameter-server:
  bind: localhost:7000
  checkpoint-dir: logs/checkpoints
  log-level: INFO

relaax-rlx-server:
  bind: localhost:7001
  log-level: INFO

version: 1.1.0
algorithm:
  name: da3c                      # short name for algorithm to load

  input:
    shape: [4]                    # shape of input state
    history: 1                    # number of consecutive states to stack
    use_convolutions: false       # set to true to process input by convolution layers

  output:
    continuous: false             # set to true to switch to continuous action space
    action_size: 2                # action size for the given environment

  hidden_sizes: []
  batch_size: 100                 # maximum batch size, which need to accumulate for one update

  use_lstm: false                 # to use LSTM instead of FF, set to the True
  max_global_step: 30000          # amount of maximum global steps to pass through the training

  entropy_beta: 0.01              # entropy regularization constant
  rewards_gamma: 0.99             # rewards discount factor

  initial_learning_rate: 0.02     # initial learning rate, which can be anneal by some procedure
  gradients_norm_clipping: false  # gradients clipping by global norm, if false then it is ignored
  optimizer: Adam                 # name of optimizer to use within training
