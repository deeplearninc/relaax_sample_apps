environment:
  run: python environment/training.py
  name: BoxingDeterministic-v4
  shape: [84, 84]
  infinite_run: True

relaax-metrics-server:
  enable_unknown_metrics: false
  metrics:
    episode_reward: true
    server_latency: false
    action: false
    mu: false
    sigma2: false
    critic: true

  bind: localhost:7002
  metrics_dir: logs/metrics
  log_metrics_to_console: false
  log_level: INFO

relaax-parameter-server:
  --bind: localhost:7000
  --checkpoint-dir: logs/checkpoints
  --log-level: INFO

relaax-rlx-server:
  --bind: localhost:7001
  --log-level: INFO

algorithm:
  name: dppo

  input:
    shape: [84, 84]
    history: 1
    use_convolutions: true
    universe: false

  output:
    continuous: false
    action_size: 18               # action size for the given environment

  batch_size: 20                   # local loop size for one episode
  hidden_sizes: [256]
  activation: elu

  use_lstm: false                 # to use LSTM instead of FF, set to the True

  gamma: 0.97             # rewards discount factor
  gradients_norm_clipping: 40.
  
  clip_e: 0.2
  learning_rate: 0.001

  combine_gradient: dc
  num_gradients: 4
  dc_lambda: 0.05
  
  policy_iterations: 25
  value_func_iterations: 25
