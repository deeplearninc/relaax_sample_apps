environment:
  run: environment/start

relaax-metrics-server:
  enable_unknown_metrics: true
  metrics:
    episode_reward: true
    server_latency: true
    action: true
    mu: false
    sigma2: false
    critic: true

  bind: localhost:7002
  metrics_dir: logs/metrics
  log_metrics_to_console: false
  log_level: INFO  # DEBUG | INFO

relaax-parameter-server:
  bind: localhost:7000
  checkpoint-dir: logs/da3c/checkpoints
  checkpoint_time_interval: 3600
  checkpoints_to_keep: 24
  log-level: INFO  # DEBUG | INFO

relaax-rlx-server:
  bind: localhost:7001
  log_level: INFO  # DEBUG | INFO

relaax-wsproxy:
  bind: localhost:9000
  log_level: INFO  # DEBUG | INFO

version: 1.1.0
algorithm:
  name: da3c                      # short name for algorithm to load

  input:
    shape: [58]                   # shape of input state
    history: 1                    # number of consecutive states to stuck to represent an input
    use_convolutions: false       # set to True to use convolutions to process the input,
                                  # it uses the set of convolutions from universe architecture by default
  output:
    continuous: true              # set to True to handle with continuous action type
    action_size: 2                # action size for the given environment
    action_high: 1.0              # upper boundary for clipping continuous action
    action_low: -1.0              # lower boundary for clipping continuous action

  batch_size: 200                 # maximum batch size, which need to accumulate for one update
  hidden_sizes: [300,300,300]     # list of num_units for hidden fc layers

  use_lstm: true                  # to use LSTM instead of FF, set to the True
  max_global_step: 1e8            # amount of maximum global steps to pass through the training

  rewards_gamma: 0.99             # rewards discount factor

  initial_learning_rate: 2e-4     # initial learning rate to start the training
  use_linear_schedule: true       # set to True to use linear learning rate annealing wrt max_global_step
  critic_scale: 10.0              # coefficient to scale the critic loss or learning rate

  optimizer: RMSProp
  gradients_norm_clipping: 50.0   # value to clip the gradients by its global norm, set to false to not

  RMSProp:                        # RMSProp optimizer specific parameters
    decay: 0.99
    epsilon: 0.1
