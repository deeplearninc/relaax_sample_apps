environment:
  run: python environment/training.py
  name: ppaquette/DoomMyWayHome-v0
  max_episodes: 10000
  infinite_run: False

metrics:
  episode_reward: true
  server_latency: false
  action: false
  mu: false
  sigma2: false
  critic: true

relaax-metrics-server:
  bind: localhost:7002
  metrics_dir: logs/metrics
  log_metrics_to_console: false
  log_level: INFO

relaax-parameter-server:
  --bind: localhost:7000
  --checkpoint-dir: logs/checkpoints
  --log-level: INFO

relaax-rlx-server:
  --bind: localhost:7001
  --log-level: INFO

algorithm:
  name: da3c

  input:
    shape: [42, 42]
    history: 1
    use_convolutions: true

  output:
    continuous: false
    action_size: 4                # action size for the given environment

  batch_size: 20                  # local loop size for one episode
  hidden_sizes: [256]

  use_icm: true                   # ICM module switcher
  use_gae: true                   # switcher for generalized advantage estimation
  gae_lambda: 1.00                # lambda for generalized advantage estimation

  use_lstm: true                  # to use LSTM instead of FF, set to the True
  max_global_step: 1e8            # amount of maximum global steps to pass through the training

  optimizer: Adam
  initial_learning_rate: 1e-4

  entropy_beta: 0.01              # entropy regularization constant
  rewards_gamma: 0.99             # rewards discount factor
  gradients_norm_clipping: 40.

  icm:                            # ICM relevant parameters
    nu: 0.01                      # prediction bonus, last=0.8
    beta: 0.2                     # forward loss importance against inverse
    lr: 1e-3                      # ICM learning rate
